{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07691106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification mlp model\n",
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "from pandas import read_csv\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0e720fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Train File (Run this if you are using Jupyter Notebook)\n",
    "df_train=read_csv('train.csv')\n",
    "dataset = df_train.values\n",
    "X, y = dataset[:, 1:-1], dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e4a05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Train File in Google Drive (Run this if you are using Google Collab)\n",
    "from google.colab import drive \n",
    "drive.mount('/content/gdrive')\n",
    "# 'gdrive/My Drive/Colab Notebooks/train.csv' -> is the example path of your csv training file in google drive\n",
    "df_train=read_csv('gdrive/My Drive/Colab Notebooks/train.csv')\n",
    "dataset = df_train.values\n",
    "X, y = dataset[:, 1:-1], dataset[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "013ffdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "[[-0.04957322  0.05148186  0.06149769 ...  0.9517357  -0.3030943\n",
      "  -0.133766  ]\n",
      " [-0.0852981   0.04864757  0.08326341 ...  0.9181289  -0.3019532\n",
      "  -0.1112807 ]\n",
      " [-0.04656757  0.05779297  0.1149698  ...  0.9588635  -0.2888554\n",
      "  -0.07875562]\n",
      " ...\n",
      " [-0.07608207 -0.1209782  -0.06041521 ...  0.9150897  -0.3452695\n",
      "  -0.05962909]\n",
      " [-0.1159183  -0.1091329  -0.075187   ...  0.8749824  -0.3334227\n",
      "  -0.07303173]\n",
      " [-0.09997093 -0.02197526 -0.08667104 ...  0.8906366  -0.2462672\n",
      "  -0.08313887]]\n",
      "------------------\n",
      "[5. 5. 5. ... 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------\")\n",
    "print(X)\n",
    "print(\"------------------\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e88ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change to float, create variable that save number of features (input) \n",
    "# and create variable that save number of class (output)\n",
    "X, y = X.astype('float'), y.astype('float')\n",
    "n_features = X.shape[1]\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "n_class = len(unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0990d3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print again after change to float and labeling the output\n",
      "------------------\n",
      "[[-0.04957322  0.05148186  0.06149769 ...  0.9517357  -0.3030943\n",
      "  -0.133766  ]\n",
      " [-0.0852981   0.04864757  0.08326341 ...  0.9181289  -0.3019532\n",
      "  -0.1112807 ]\n",
      " [-0.04656757  0.05779297  0.1149698  ...  0.9588635  -0.2888554\n",
      "  -0.07875562]\n",
      " ...\n",
      " [-0.07608207 -0.1209782  -0.06041521 ...  0.9150897  -0.3452695\n",
      "  -0.05962909]\n",
      " [-0.1159183  -0.1091329  -0.075187   ...  0.8749824  -0.3334227\n",
      "  -0.07303173]\n",
      " [-0.09997093 -0.02197526 -0.08667104 ...  0.8906366  -0.2462672\n",
      "  -0.08313887]]\n",
      "------------------\n",
      "[4 4 4 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Print again after change to float and labeling the output\")\n",
    "print(\"------------------\")\n",
    "print(X)\n",
    "print(\"------------------\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d9ae545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "n_features 9\n",
      "------------------\n",
      "n_class 6\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------\")\n",
    "print(f\"n_features {n_features}\")\n",
    "print(\"------------------\")\n",
    "print(f\"n_class {n_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2460a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load TEST FILE and change input and output to float (Run this if you are using Jupyter Notebook)\n",
    "df_test=read_csv('test.csv')\n",
    "dataset_test = df_test.values\n",
    "X_test, y_test = dataset_test[:, 1:-1], dataset_test[:, -1]\n",
    "X_test, y_test = X_test.astype('float'), y_test.astype('float')\n",
    "y_test = LabelEncoder().fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b98f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load TEST FILE and change input and output to float (Run this if you are using Google Collab)\n",
    "df_test=read_csv('gdrive/My Drive/Colab Notebooks/test.csv')\n",
    "dataset_test = df_test.values\n",
    "X_test, y_test = dataset_test[:, 1:-1], dataset_test[:, -1]\n",
    "X_test, y_test = X_test.astype('float'), y_test.astype('float')\n",
    "y_test = LabelEncoder().fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcdd568e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Test variables\n",
      "------------------\n",
      "[[ 0.01165315 -0.02939904  0.1068262  ...  1.041216   -0.2697959\n",
      "   0.02377977]\n",
      " [ 0.01310909 -0.03972867  0.1524549  ...  1.041803   -0.280025\n",
      "   0.07629271]\n",
      " [ 0.01126885 -0.05240586  0.2168462  ...  1.039086   -0.2926631\n",
      "   0.1474754 ]\n",
      " ...\n",
      " [-0.07190685 -0.1943222  -0.1275547  ...  0.8980947  -0.3977751\n",
      "  -0.156105  ]\n",
      " [-0.1422088  -0.1470701  -0.09236675 ...  0.8283723  -0.3492473\n",
      "  -0.1227979 ]\n",
      " [-0.1709989  -0.1313991  -0.05112688 ...  0.8002428  -0.3323721\n",
      "  -0.08357159]]\n",
      "------------------\n",
      "[4 4 4 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Print Test variables\")\n",
    "print(\"------------------\")\n",
    "print(X_test)\n",
    "print(\"------------------\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd549b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "16508/16508 - 9s - loss: 0.4787\n",
      "Epoch 2/150\n",
      "16508/16508 - 8s - loss: 0.3699\n",
      "Epoch 3/150\n",
      "16508/16508 - 8s - loss: 0.3527\n",
      "Epoch 4/150\n",
      "16508/16508 - 8s - loss: 0.3432\n",
      "Epoch 5/150\n",
      "16508/16508 - 8s - loss: 0.3349\n",
      "Epoch 6/150\n",
      "16508/16508 - 8s - loss: 0.3286\n",
      "Epoch 7/150\n",
      "16508/16508 - 8s - loss: 0.3242\n",
      "Epoch 8/150\n",
      "16508/16508 - 8s - loss: 0.3212\n",
      "Epoch 9/150\n",
      "16508/16508 - 8s - loss: 0.3184\n",
      "Epoch 10/150\n",
      "16508/16508 - 8s - loss: 0.3162\n",
      "Epoch 11/150\n",
      "16508/16508 - 8s - loss: 0.3141\n",
      "Epoch 12/150\n",
      "16508/16508 - 8s - loss: 0.3125\n",
      "Epoch 13/150\n",
      "16508/16508 - 8s - loss: 0.3106\n",
      "Epoch 14/150\n",
      "16508/16508 - 8s - loss: 0.3089\n",
      "Epoch 15/150\n",
      "16508/16508 - 8s - loss: 0.3073\n",
      "Epoch 16/150\n",
      "16508/16508 - 8s - loss: 0.3056\n",
      "Epoch 17/150\n",
      "16508/16508 - 8s - loss: 0.3038\n",
      "Epoch 18/150\n",
      "16508/16508 - 9s - loss: 0.3022\n",
      "Epoch 19/150\n",
      "16508/16508 - 8s - loss: 0.3008\n",
      "Epoch 20/150\n",
      "16508/16508 - 8s - loss: 0.2998\n",
      "Epoch 21/150\n",
      "16508/16508 - 8s - loss: 0.2987\n",
      "Epoch 22/150\n",
      "16508/16508 - 8s - loss: 0.2977\n",
      "Epoch 23/150\n",
      "16508/16508 - 8s - loss: 0.2972\n",
      "Epoch 24/150\n",
      "16508/16508 - 7s - loss: 0.2961\n",
      "Epoch 25/150\n",
      "16508/16508 - 8s - loss: 0.2956\n",
      "Epoch 26/150\n",
      "16508/16508 - 8s - loss: 0.2949\n",
      "Epoch 27/150\n",
      "16508/16508 - 9s - loss: 0.2945\n",
      "Epoch 28/150\n",
      "16508/16508 - 8s - loss: 0.2936\n",
      "Epoch 29/150\n",
      "16508/16508 - 8s - loss: 0.2933\n",
      "Epoch 30/150\n",
      "16508/16508 - 8s - loss: 0.2926\n",
      "Epoch 31/150\n",
      "16508/16508 - 8s - loss: 0.2921\n",
      "Epoch 32/150\n",
      "16508/16508 - 7s - loss: 0.2917\n",
      "Epoch 33/150\n",
      "16508/16508 - 8s - loss: 0.2915\n",
      "Epoch 34/150\n",
      "16508/16508 - 7s - loss: 0.2911\n",
      "Epoch 35/150\n",
      "16508/16508 - 8s - loss: 0.2908\n",
      "Epoch 36/150\n",
      "16508/16508 - 8s - loss: 0.2903\n",
      "Epoch 37/150\n",
      "16508/16508 - 8s - loss: 0.2897\n",
      "Epoch 38/150\n",
      "16508/16508 - 8s - loss: 0.2891\n",
      "Epoch 39/150\n",
      "16508/16508 - 7s - loss: 0.2887\n",
      "Epoch 40/150\n",
      "16508/16508 - 7s - loss: 0.2883\n",
      "Epoch 41/150\n",
      "16508/16508 - 8s - loss: 0.2882\n",
      "Epoch 42/150\n",
      "16508/16508 - 7s - loss: 0.2877\n",
      "Epoch 43/150\n",
      "16508/16508 - 8s - loss: 0.2874\n",
      "Epoch 44/150\n",
      "16508/16508 - 7s - loss: 0.2873\n",
      "Epoch 45/150\n",
      "16508/16508 - 7s - loss: 0.2870\n",
      "Epoch 46/150\n",
      "16508/16508 - 8s - loss: 0.2863\n",
      "Epoch 47/150\n",
      "16508/16508 - 7s - loss: 0.2859\n",
      "Epoch 48/150\n",
      "16508/16508 - 8s - loss: 0.2856\n",
      "Epoch 49/150\n",
      "16508/16508 - 7s - loss: 0.2853\n",
      "Epoch 50/150\n",
      "16508/16508 - 8s - loss: 0.2848\n",
      "Epoch 51/150\n",
      "16508/16508 - 7s - loss: 0.2849\n",
      "Epoch 52/150\n",
      "16508/16508 - 8s - loss: 0.2845\n",
      "Epoch 53/150\n",
      "16508/16508 - 8s - loss: 0.2842\n",
      "Epoch 54/150\n",
      "16508/16508 - 8s - loss: 0.2844\n",
      "Epoch 55/150\n",
      "16508/16508 - 8s - loss: 0.2842\n",
      "Epoch 56/150\n",
      "16508/16508 - 8s - loss: 0.2840\n",
      "Epoch 57/150\n",
      "16508/16508 - 7s - loss: 0.2839\n",
      "Epoch 58/150\n",
      "16508/16508 - 8s - loss: 0.2836\n",
      "Epoch 59/150\n",
      "16508/16508 - 7s - loss: 0.2833\n",
      "Epoch 60/150\n",
      "16508/16508 - 8s - loss: 0.2833\n",
      "Epoch 61/150\n",
      "16508/16508 - 7s - loss: 0.2832\n",
      "Epoch 62/150\n",
      "16508/16508 - 8s - loss: 0.2832\n",
      "Epoch 63/150\n",
      "16508/16508 - 8s - loss: 0.2829\n",
      "Epoch 64/150\n",
      "16508/16508 - 7s - loss: 0.2832\n",
      "Epoch 65/150\n",
      "16508/16508 - 8s - loss: 0.2828\n",
      "Epoch 66/150\n",
      "16508/16508 - 7s - loss: 0.2825\n",
      "Epoch 67/150\n",
      "16508/16508 - 8s - loss: 0.2826\n",
      "Epoch 68/150\n",
      "16508/16508 - 8s - loss: 0.2823\n",
      "Epoch 69/150\n",
      "16508/16508 - 8s - loss: 0.2823\n",
      "Epoch 70/150\n",
      "16508/16508 - 7s - loss: 0.2821\n",
      "Epoch 71/150\n",
      "16508/16508 - 8s - loss: 0.2820\n",
      "Epoch 72/150\n",
      "16508/16508 - 7s - loss: 0.2818\n",
      "Epoch 73/150\n",
      "16508/16508 - 8s - loss: 0.2817\n",
      "Epoch 74/150\n",
      "16508/16508 - 7s - loss: 0.2814\n",
      "Epoch 75/150\n",
      "16508/16508 - 8s - loss: 0.2812\n",
      "Epoch 76/150\n",
      "16508/16508 - 7s - loss: 0.2810\n",
      "Epoch 77/150\n",
      "16508/16508 - 8s - loss: 0.2809\n",
      "Epoch 78/150\n",
      "16508/16508 - 7s - loss: 0.2808\n",
      "Epoch 79/150\n",
      "16508/16508 - 9s - loss: 0.2806\n",
      "Epoch 80/150\n",
      "16508/16508 - 7s - loss: 0.2806\n",
      "Epoch 81/150\n",
      "16508/16508 - 8s - loss: 0.2805\n",
      "Epoch 82/150\n",
      "16508/16508 - 7s - loss: 0.2803\n",
      "Epoch 83/150\n",
      "16508/16508 - 7s - loss: 0.2803\n",
      "Epoch 84/150\n",
      "16508/16508 - 7s - loss: 0.2801\n",
      "Epoch 85/150\n",
      "16508/16508 - 8s - loss: 0.2796\n",
      "Epoch 86/150\n",
      "16508/16508 - 8s - loss: 0.2796\n",
      "Epoch 87/150\n",
      "16508/16508 - 8s - loss: 0.2794\n",
      "Epoch 88/150\n",
      "16508/16508 - 8s - loss: 0.2791\n",
      "Epoch 89/150\n",
      "16508/16508 - 7s - loss: 0.2791\n",
      "Epoch 90/150\n",
      "16508/16508 - 8s - loss: 0.2786\n",
      "Epoch 91/150\n",
      "16508/16508 - 7s - loss: 0.2784\n",
      "Epoch 92/150\n",
      "16508/16508 - 8s - loss: 0.2782\n",
      "Epoch 93/150\n",
      "16508/16508 - 8s - loss: 0.2780\n",
      "Epoch 94/150\n",
      "16508/16508 - 8s - loss: 0.2779\n",
      "Epoch 95/150\n",
      "16508/16508 - 8s - loss: 0.2779\n",
      "Epoch 96/150\n",
      "16508/16508 - 9s - loss: 0.2774\n",
      "Epoch 97/150\n",
      "16508/16508 - 9s - loss: 0.2774\n",
      "Epoch 98/150\n",
      "16508/16508 - 8s - loss: 0.2775\n",
      "Epoch 99/150\n",
      "16508/16508 - 9s - loss: 0.2773\n",
      "Epoch 100/150\n",
      "16508/16508 - 8s - loss: 0.2772\n",
      "Epoch 101/150\n",
      "16508/16508 - 8s - loss: 0.2771\n",
      "Epoch 102/150\n",
      "16508/16508 - 8s - loss: 0.2771\n",
      "Epoch 103/150\n",
      "16508/16508 - 8s - loss: 0.2768\n",
      "Epoch 104/150\n",
      "16508/16508 - 8s - loss: 0.2765\n",
      "Epoch 105/150\n",
      "16508/16508 - 8s - loss: 0.2766\n",
      "Epoch 106/150\n",
      "16508/16508 - 8s - loss: 0.2766\n",
      "Epoch 107/150\n",
      "16508/16508 - 7s - loss: 0.2766\n",
      "Epoch 108/150\n",
      "16508/16508 - 8s - loss: 0.2762\n",
      "Epoch 109/150\n",
      "16508/16508 - 8s - loss: 0.2764\n",
      "Epoch 110/150\n",
      "16508/16508 - 8s - loss: 0.2761\n",
      "Epoch 111/150\n",
      "16508/16508 - 8s - loss: 0.2763\n",
      "Epoch 112/150\n",
      "16508/16508 - 8s - loss: 0.2759\n",
      "Epoch 113/150\n",
      "16508/16508 - 7s - loss: 0.2760\n",
      "Epoch 114/150\n",
      "16508/16508 - 8s - loss: 0.2758\n",
      "Epoch 115/150\n",
      "16508/16508 - 8s - loss: 0.2756\n",
      "Epoch 116/150\n",
      "16508/16508 - 8s - loss: 0.2756\n",
      "Epoch 117/150\n",
      "16508/16508 - 7s - loss: 0.2755\n",
      "Epoch 118/150\n",
      "16508/16508 - 8s - loss: 0.2754\n",
      "Epoch 119/150\n",
      "16508/16508 - 7s - loss: 0.2753\n",
      "Epoch 120/150\n",
      "16508/16508 - 8s - loss: 0.2752\n",
      "Epoch 121/150\n",
      "16508/16508 - 8s - loss: 0.2753\n",
      "Epoch 122/150\n",
      "16508/16508 - 7s - loss: 0.2751\n",
      "Epoch 123/150\n",
      "16508/16508 - 8s - loss: 0.2749\n",
      "Epoch 124/150\n",
      "16508/16508 - 8s - loss: 0.2749\n",
      "Epoch 125/150\n",
      "16508/16508 - 8s - loss: 0.2749\n",
      "Epoch 126/150\n",
      "16508/16508 - 8s - loss: 0.2748\n",
      "Epoch 127/150\n",
      "16508/16508 - 8s - loss: 0.2748\n",
      "Epoch 128/150\n",
      "16508/16508 - 8s - loss: 0.2747\n",
      "Epoch 129/150\n",
      "16508/16508 - 8s - loss: 0.2743\n",
      "Epoch 130/150\n",
      "16508/16508 - 8s - loss: 0.2745\n",
      "Epoch 131/150\n",
      "16508/16508 - 8s - loss: 0.2745\n",
      "Epoch 132/150\n",
      "16508/16508 - 7s - loss: 0.2741\n",
      "Epoch 133/150\n",
      "16508/16508 - 8s - loss: 0.2740\n",
      "Epoch 134/150\n",
      "16508/16508 - 7s - loss: 0.2740\n",
      "Epoch 135/150\n",
      "16508/16508 - 8s - loss: 0.2736\n",
      "Epoch 136/150\n",
      "16508/16508 - 7s - loss: 0.2734\n",
      "Epoch 137/150\n",
      "16508/16508 - 8s - loss: 0.2732\n",
      "Epoch 138/150\n",
      "16508/16508 - 8s - loss: 0.2730\n",
      "Epoch 139/150\n",
      "16508/16508 - 8s - loss: 0.2727\n",
      "Epoch 140/150\n",
      "16508/16508 - 7s - loss: 0.2724\n",
      "Epoch 141/150\n",
      "16508/16508 - 8s - loss: 0.2719\n",
      "Epoch 142/150\n",
      "16508/16508 - 8s - loss: 0.2715\n",
      "Epoch 143/150\n",
      "16508/16508 - 8s - loss: 0.2712\n",
      "Epoch 144/150\n",
      "16508/16508 - 8s - loss: 0.2708\n",
      "Epoch 145/150\n",
      "16508/16508 - 8s - loss: 0.2704\n",
      "Epoch 146/150\n",
      "16508/16508 - 7s - loss: 0.2702\n",
      "Epoch 147/150\n",
      "16508/16508 - 7s - loss: 0.2698\n",
      "Epoch 148/150\n",
      "16508/16508 - 8s - loss: 0.2697\n",
      "Epoch 149/150\n",
      "16508/16508 - 7s - loss: 0.2692\n",
      "Epoch 150/150\n",
      "16508/16508 - 8s - loss: 0.2693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x236559dd910>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=n_features, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(n_class, activation='softmax'))\n",
    "# compile the keras model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a78c184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.730\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "yhat = model.predict(X_test)\n",
    "yhat = argmax(yhat, axis=-1).astype('int')\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99616eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.730437\n"
     ]
    }
   ],
   "source": [
    "# F1 Score\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test, yhat, average='weighted')\n",
    "print('F1 score: %f' % f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
